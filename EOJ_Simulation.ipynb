{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import dill\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import ot\n",
    "from p_tqdm import p_map\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.settings['recurse'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"C:\\\\Users\\\\oconn\\\\Dropbox\\\\Research\\\\EstimationOfOJ\\\\Simulation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov and Hidden Markov Chain Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChain:\n",
    "    def __init__(self, transition_matrix, states):\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.stationary_distribution = self.get_stationary_distribution(transition_matrix)\n",
    "        self.states = states\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_stationary_distribution(transition_matrix):\n",
    "        eig_vals, eig_vecs = np.linalg.eig(transition_matrix)\n",
    "        stationary_distribution = np.real(eig_vecs[:, np.isclose(eig_vals, 1)][:, 0])\n",
    "        stationary_distribution /= np.sum(stationary_distribution)\n",
    "        return stationary_distribution\n",
    "        \n",
    "    def sample(self, n):\n",
    "        sampled_idxs = []\n",
    "        \n",
    "        # Sample from stationary distribution first\n",
    "        sampled_idxs.append(np.random.choice(len(self.states), p=self.stationary_distribution))\n",
    "        \n",
    "        # Sample remaining from transition matrix\n",
    "        for i in range(1, n):\n",
    "            sampled_idxs.append(np.random.choice(\n",
    "                len(self.states), \n",
    "                p=self.transition_matrix[sampled_idxs[-1],:]\n",
    "            ))\n",
    "\n",
    "        return [self.states[i] for i in sampled_idxs]\n",
    "    \n",
    "    \n",
    "class HiddenMarkovChain:\n",
    "    def __init__(self, transition_matrix, emission_matrix, states):\n",
    "        self.markov_chain = MarkovChain(transition_matrix, list(np.arange(transition_matrix.shape[0])))\n",
    "        self.emission_matrix = emission_matrix\n",
    "        self.states = states\n",
    "                \n",
    "    def sample(self, n):\n",
    "        latent_samples = self.markov_chain.sample(n)\n",
    "        \n",
    "        sampled_idxs = []\n",
    "        for i in range(n):\n",
    "            sampled_idxs.append(np.random.choice(\n",
    "                len(self.states),\n",
    "                p=self.emission_matrix[latent_samples[i],:]\n",
    "            ))\n",
    "        \n",
    "        return [self.states[i] for i in sampled_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mc(n_states):\n",
    "    transition_matrix = np.abs(np.random.normal(size=(n_states, n_states)))\n",
    "    transition_matrix = transition_matrix / np.sum(transition_matrix, axis=1)[:,None]\n",
    "\n",
    "    return MarkovChain(\n",
    "        transition_matrix=transition_matrix,\n",
    "        states=np.linspace(1, n_states, num=n_states, dtype=np.int32)\n",
    "    )\n",
    "\n",
    "\n",
    "def gen_hmm(n_hidden_states, n_states):\n",
    "    transition_matrix = np.abs(np.random.normal(size=(n_hidden_states, n_hidden_states)))\n",
    "    transition_matrix = transition_matrix / np.sum(transition_matrix, axis=1)[:,None]\n",
    "    \n",
    "    emission_matrix = np.abs(np.random.normal(size=(n_hidden_states, n_states)))\n",
    "    emission_matrix = emission_matrix / np.sum(emission_matrix, axis=1)[:,None]\n",
    "    \n",
    "    return HiddenMarkovChain(\n",
    "        transition_matrix=transition_matrix,\n",
    "        emission_matrix=emission_matrix,\n",
    "        states=np.linspace(1, n_states, num=n_states, dtype=np.int32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Joining Estimation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kblock_measure(x_arr, k):\n",
    "    n = len(x_arr)\n",
    "    prob_dict = {}\n",
    "    for i in range(n-k+1):\n",
    "        block = tuple(x_arr[i:(i+k)])\n",
    "        if block in prob_dict:\n",
    "            prob_dict[block] += 1/n\n",
    "        else:\n",
    "            prob_dict[block] = 1/n\n",
    "    return prob_dict\n",
    "\n",
    "def get_cost_dict(mu, nu, c):\n",
    "    cost_dict = {}\n",
    "    for block_x in mu:\n",
    "        for block_y in nu:\n",
    "            cost_dict[block_x, block_y] = np.mean(np.array([c(x, y) for x, y in zip(block_x, block_y)]))\n",
    "    return cost_dict\n",
    "\n",
    "def melt_coupling(coupling_arr, x_block_arr, y_block_arr):\n",
    "    support_points = zip(np.where(coupling_arr > 0)[0], np.where(coupling_arr > 0)[1])\n",
    "    _list = []\n",
    "    for i, j in support_points:\n",
    "        _list.append(pd.DataFrame({\n",
    "            \"x_block\": [x_block_arr[i]],\n",
    "            \"y_block\": [y_block_arr[j]],\n",
    "            \"probability\": [coupling_arr[i, j]]\n",
    "        }))\n",
    "        \n",
    "    return pd.concat(_list).sort_values(\"probability\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def display_coupling(melted_coupling, n_points=10):\n",
    "    display(\n",
    "        melted_coupling\n",
    "        .head(n_points)\n",
    "        .style\n",
    "        .background_gradient(subset=\"probability\")\n",
    "        .set_precision(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_oj(x_arr, y_arr, c, k, reg=0, mode=\"cost\"):\n",
    "    # Args:\n",
    "    # - x_arr, y_arr: numpy arrays containing observed sequences\n",
    "    # - c: cost function\n",
    "    # - k: block size\n",
    "    # - reg: regularization coefficient\n",
    "    # - mode: \"cost\", \"cost-time\", or \"all\"\n",
    "    \n",
    "    # Construct k-block measures\n",
    "    mu_dict = get_kblock_measure(x_arr, k)\n",
    "    nu_dict = get_kblock_measure(y_arr, k)\n",
    "\n",
    "    # Construct cost matrix\n",
    "    cost_dict = get_cost_dict(mu_dict, nu_dict, c)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    x_block_arr = list(mu_dict.keys())\n",
    "    mu = np.array([mu_dict[x_block] for x_block in x_block_arr])\n",
    "    y_block_arr = list(nu_dict.keys())\n",
    "    nu = np.array([nu_dict[y_block] for y_block in y_block_arr])\n",
    "    cost_mat = np.array([[cost_dict[x_block, y_block] for y_block in y_block_arr] for x_block in x_block_arr])\n",
    "    \n",
    "    # Solve OT problem\n",
    "    start_time = time.time()\n",
    "    if reg == 0:\n",
    "        coupling_arr = ot.emd(mu, nu, cost_mat)\n",
    "    else:\n",
    "        coupling_arr = ot.sinkhorn(mu, nu, cost_mat, reg/k, method=\"sinkhorn\", stopThr=1e-4)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    estimated_cost = np.sum(coupling_arr*cost_mat)\n",
    "    if mode == \"cost\":\n",
    "        return estimated_cost\n",
    "    elif mode == \"cost-time\":\n",
    "        return estimated_cost, total_time, start_time, end_time\n",
    "    elif mode == \"all\":\n",
    "        return (x_block_arr, mu), (y_block_arr, nu), coupling_arr, np.sum(coupling_arr*cost_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Estimated OJ Cost as a Function of n and k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_for_grid(x_arr, y_arr, step_size=1):\n",
    "    c = lambda x, y: int(x != y)\n",
    "    n_grid = np.arange(10, len(x_arr), step=step_size, dtype=np.int32)\n",
    "    \n",
    "    _list = []\n",
    "    for n in tqdm(n_grid):\n",
    "        k_grid = np.arange(1, n, step=step_size, dtype=np.int32)\n",
    "        for k in k_grid:\n",
    "            oj_cost, total_time = estimate_oj(x_arr[:n], y_arr[:n], c, k, reg=0, mode=\"cost-time\")\n",
    "            _list.append(pd.DataFrame({\n",
    "                \"n\": [n],\n",
    "                \"k\": [k],\n",
    "                \"estimated_cost\": [oj_cost],\n",
    "                \"time\": [total_time]\n",
    "            }))\n",
    "\n",
    "    return pd.concat(_list, ignore_index=True).pivot(\"k\", \"n\", \"estimated_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_for_logn(x_arr, y_arr, step_size=1, reg=0):\n",
    "    c = lambda x, y: int(x != y)\n",
    "    n_grid = np.arange(50, len(x_arr)+1, step=step_size, dtype=np.int32)\n",
    "    \n",
    "    _list = []\n",
    "    for n in n_grid:\n",
    "        k = max(int(0.25*np.log2(n)), 1)\n",
    "        oj_cost, _, _, _ = estimate_oj(x_arr[:n], y_arr[:n], c, k, reg=reg, mode=\"cost-time\")\n",
    "        _list.append(pd.DataFrame({\n",
    "            \"n\": [n],\n",
    "            \"k\": [k],\n",
    "            \"estimated_cost\": [oj_cost],\n",
    "        }))\n",
    "\n",
    "    return pd.concat(_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cost_convergence_experiment(sampling_func1, sampling_func2, n_iter, max_n, reg, exp_dir, run_name):        \n",
    "    def iter_func(i):\n",
    "        x_arr = sampling_func1(max_n)\n",
    "        y_arr = sampling_func2(max_n)\n",
    "\n",
    "        # Without regularization\n",
    "        df = compute_cost_for_logn(x_arr, y_arr, step_size=50)\n",
    "        df[\"reg\"] = 0\n",
    "        \n",
    "        # With regularization\n",
    "        df_reg = compute_cost_for_logn(x_arr, y_arr, step_size=50, reg=reg)\n",
    "        df_reg[\"reg\"] = reg\n",
    "        \n",
    "        return pd.concat([df, df_reg], ignore_index=True)\n",
    "    \n",
    "    list_df = p_map(iter_func, list(range(n_iter)))\n",
    "    \n",
    "    results_df = (\n",
    "        pd.concat(list_df)\n",
    "        .groupby([\"n\", \"reg\"])\n",
    "        .agg(\n",
    "            mean=(\"estimated_cost\", np.mean),\n",
    "            sd=(\"estimated_cost\", np.std),\n",
    "            lower_quantile=(\"estimated_cost\", lambda x: np.quantile(x, q=0.025)),\n",
    "            upper_quantile=(\"estimated_cost\", lambda x: np.quantile(x, q=0.975))\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    results_df[\"lower_sd\"] = np.maximum(results_df[\"mean\"] - 2*results_df[\"sd\"], 0)\n",
    "    results_df[\"upper_sd\"] = np.minimum(results_df[\"mean\"] + 2*results_df[\"sd\"], 1)\n",
    "        \n",
    "    file_name = run_name + \"_results_df.pkl\"\n",
    "    results_df.to_pickle(os.path.join(exp_dir, file_name))\n",
    "        \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def plot_cost_convergence_results(results_df, name):\n",
    "    for reg, _df in results_df.groupby(\"reg\"):\n",
    "        plt.plot(_df[\"n\"], _df[\"mean\"], label=\"reg={}\".format(reg))\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    for reg, _df in results_df.groupby(\"reg\"):\n",
    "        plt.fill_between(_df[\"n\"], _df[\"lower_sd\"], _df[\"upper_sd\"], alpha=0.3, label=\"reg={}\".format(reg))\n",
    "\n",
    "    plt.xlabel(\"n\")\n",
    "    plt.ylabel(\"Estimated Cost\")\n",
    "    plt.title(name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment directory\n",
    "exp_id = ''.join(c for c in str(dt.datetime.now()) if c.isdigit())\n",
    "exp_dir = os.path.join(output_dir, \"cost_convergence\", exp_id)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "print(exp_dir)\n",
    "\n",
    "\n",
    "# Experiment parameters\n",
    "max_n = 2500\n",
    "n_iter = 50\n",
    "reg = 5e-1\n",
    "\n",
    "\n",
    "# Identical Markov Chains\n",
    "print(\"identical Markov chains\")\n",
    "mc = gen_mc(n_states=2)\n",
    "results_df = run_cost_convergence_experiment(\n",
    "    sampling_func1=mc.sample,\n",
    "    sampling_func2=mc.sample,\n",
    "    n_iter=n_iter,\n",
    "    max_n=max_n,\n",
    "    reg=reg,\n",
    "    exp_dir=exp_dir,\n",
    "    run_name=\"identical_markov_chains\"\n",
    ")\n",
    "plot_cost_convergence_results(results_df, name=\"Identical Markov Chains\")\n",
    "\n",
    "\n",
    "# Identical HMMs\n",
    "print(\"identical HMMs\")\n",
    "hmm = gen_hmm(n_hidden_states=5, n_states=2)\n",
    "results_df = run_cost_convergence_experiment(\n",
    "    sampling_func1=hmm.sample,\n",
    "    sampling_func2=hmm.sample,\n",
    "    n_iter=n_iter,\n",
    "    max_n=max_n,\n",
    "    reg=reg,\n",
    "    exp_dir=exp_dir,\n",
    "    run_name=\"identical_hmms\"\n",
    ")\n",
    "plot_cost_convergence_results(results_df, name=\"Identical HMMs\")\n",
    "\n",
    "\n",
    "# MC vs MC\n",
    "print(\"MC vs MC\")\n",
    "mc1 = gen_mc(n_states=2)\n",
    "mc2 = gen_mc(n_states=2)\n",
    "results_df = run_cost_convergence_experiment(\n",
    "    sampling_func1=mc1.sample,\n",
    "    sampling_func2=mc2.sample,\n",
    "    n_iter=n_iter,\n",
    "    max_n=max_n,\n",
    "    reg=reg,\n",
    "    exp_dir=exp_dir,\n",
    "    run_name=\"mc_vs_mc\"\n",
    ")\n",
    "plot_cost_convergence_results(results_df, name=\"Markov Chain vs Markov Chain\")\n",
    "\n",
    "\n",
    "# HMM vs HMM\n",
    "print(\"HMM vs HMM\")\n",
    "hmm1 = gen_hmm(n_hidden_states=5, n_states=2)\n",
    "hmm2 = gen_hmm(n_hidden_states=5, n_states=2)\n",
    "results_df = run_cost_convergence_experiment(\n",
    "    sampling_func1=hmm1.sample,\n",
    "    sampling_func2=hmm2.sample,\n",
    "    n_iter=n_iter,\n",
    "    max_n=max_n,\n",
    "    reg=reg,\n",
    "    exp_dir=exp_dir,\n",
    "    run_name=\"hmm_vs_hmm\"\n",
    ")\n",
    "plot_cost_convergence_results(results_df, name=\"HMM vs HMM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Runtime for Entropic OJ Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "n_grid = [1000, 1500, 2000, 2500]\n",
    "reg_grid = [1e-1, 1.5e-1, 2e-1]\n",
    "\n",
    "c = lambda x, y: int(x != y)\n",
    "\n",
    "n_hidden_states = 100\n",
    "n_states = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list = []\n",
    "for n in n_grid:\n",
    "    print(\"n={}\".format(n))\n",
    "    k = max(int(0.5*np.log2(n)), 1)\n",
    "    for _ in tqdm(range(n_iter)):\n",
    "        hmm1 = gen_hmm(n_hidden_states, n_states)\n",
    "        hmm2 = gen_hmm(n_hidden_states, n_states)\n",
    "        \n",
    "        x_arr = hmm1.sample(n)\n",
    "        y_arr = hmm2.sample(n)\n",
    "\n",
    "        for reg in reg_grid:\n",
    "            est_cost, total_time, start_time, end_time = estimate_oj(x_arr, y_arr, c, k, reg=0, mode=\"cost-time\")\n",
    "            est_cost_reg, total_time_reg, start_time_reg, end_time_reg = estimate_oj(x_arr, y_arr, c, k, reg=reg, mode=\"cost-time\")\n",
    "            _list.append(pd.DataFrame({\n",
    "                \"n\": [n],\n",
    "                \"k\": [k],\n",
    "                \"est_cost\": [est_cost],\n",
    "                \"est_cost_reg\": [est_cost_reg],\n",
    "                \"total_time\": [total_time],\n",
    "                \"total_time_reg\": [total_time_reg],\n",
    "                \"start_time\": [start_time],\n",
    "                \"end_time\": [end_time],\n",
    "                \"start_time_reg\": [start_time_reg],\n",
    "                \"end_time_reg\": [end_time_reg],\n",
    "                \"reg\": [reg]\n",
    "            }))\n",
    "\n",
    "results_df = pd.concat(_list, ignore_index=True)\n",
    "\n",
    "results_df[\"time_diff\"] = results_df[\"total_time\"] - results_df[\"total_time_reg\"]\n",
    "results_df[\"time_diff_pct\"] = 100 * results_df[\"time_diff\"] / results_df[\"total_time\"]\n",
    "results_df[\"cost_diff\"] = (results_df[\"est_cost_reg\"] - results_df[\"est_cost\"]).abs()\n",
    "results_df[\"cost_diff_pct\"] = 100 * results_df[\"cost_diff\"] / results_df[\"est_cost\"]\n",
    "\n",
    "exp_id = ''.join(c for c in str(dt.datetime.now()) if c.isdigit())\n",
    "exp_dir = os.path.join(output_dir, exp_id)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "results_df.to_pickle(os.path.join(exp_dir, \"time_df.pkl\"))\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
